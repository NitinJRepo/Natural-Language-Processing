{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><u><H1>Stemming and Lemmatization</H1></u></center><br>\n",
    "Stemming and Lemmatization are Text Normalization (or sometimes called Word Normalization) techniques in the field of Natural Language Processing that are used to prepare text, words, and documents for further processing.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming:\n",
    "Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem(root) itself is not a valid word in the Language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer, LancasterStemmer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_stemmer(words, type=\"PorterStemmer\", lang=\"english\", encoding=\"utf8\"):\n",
    "    stemmers = [\"PorterStemmer\", \"LancasterStemmer\", \"SnowballStemmer\"]\n",
    "    \n",
    "    if type is False or type not in stemmers:\n",
    "        return words\n",
    "    else:\n",
    "        stem_words = []\n",
    "        if type == \"PorterStemmer\":\n",
    "            stemmer = PorterStemmer()\n",
    "            for w in words:\n",
    "                stem_words.append(stemmer.stem(w).encode(encoding))\n",
    "        if type == \"LancasterStemmer\":\n",
    "            stemmer = LancasterStemmer()\n",
    "            for w in words:\n",
    "                stem_words.append(stemmer.stem(w).encode(encoding))\n",
    "        if type == \"SnowballStemmer\":\n",
    "            stemmer = SnowballStemmer(lang)\n",
    "            for w in words:\n",
    "                stem_words.append(stemmer.stem(w).encode(encoding))\n",
    "        return b\" \".join(stem_words)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \"caring cares carefully cared\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['caring', 'cares', 'carefully', 'cared']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt = nltk.word_tokenize(words)\n",
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: caring cares carefully cared\n",
      "Porter:  b'care care care care'\n",
      "Lancaster:  b'car car car car'\n",
      "Snowball:  b'care care care care'\n"
     ]
    }
   ],
   "source": [
    "print(\"Original:\", words)\n",
    "print(\"Porter: \", words_stemmer(wt, \"PorterStemmer\"))\n",
    "print(\"Lancaster: \", words_stemmer(wt, \"LancasterStemmer\"))\n",
    "print(\"Snowball: \", words_stemmer(wt, \"SnowballStemmer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization:\n",
    "Lemmatization, unlike Stemming, reduces the inflected words properly ensuring that the root word belongs to the language. In Lemmatization root word is called Lemma. A lemma (plural lemmas or lemmata) is the canonical form, dictionary form of a set of words.<br>\n",
    "Lemmatization takes into consideration the morphological analysis of the words. To do so, it is necessary to have detailed dictionaries which the algorithm can look through to link the form back to its lemma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to apply lemmatization to list of words\n",
    "def words_lemmatizer(text, encoding=\"utf8\"):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemma_words = []\n",
    "    wl = WordNetLemmatizer()\n",
    "    \n",
    "    for w in words:\n",
    "        pos = find_pos(w)\n",
    "        lemma_words.append(wl.lemmatize(w, pos).encode(encoding))\n",
    "    return b\" \".join(lemma_words)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n    NOUN \n",
    "#v    VERB \n",
    "#a    ADJECTIVE \n",
    "#s    ADJECTIVE SATELLITE \n",
    "#r    ADVERB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pos(word):\n",
    "    #part of speech constants\n",
    "    pos = nltk.pos_tag(nltk.word_tokenize(word))[0][1]\n",
    "    # Adjective tags : \"JJ\", \"JJR\", \"JJS\"\n",
    "    if pos.lower()[0] == 'j':\n",
    "        return 'a'\n",
    "    # Adverb tags : \"RB\", \"RBR\", \"RBS\"\n",
    "    elif pos.lower()[0] == 'r':\n",
    "        return 'r'\n",
    "    # Verb tags: \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"\n",
    "    elif pos.lower()[0] == 'v':\n",
    "        return 'v'\n",
    "    # Noun tags: \"NN\", \"NNS\", \"NNP\", \"NNPS\"\n",
    "    else:\n",
    "        return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized:  b'care care carefully care'\n"
     ]
    }
   ],
   "source": [
    "print(\"Lemmatized: \", words_lemmatizer(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting synonyms and antonyms for a given word with wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordnet is a large lexical database for English words that are linked together\n",
    "# by their semantic relationships. \n",
    "# It groups words together based on their meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definition:  meant or adapted for an occasion or use\n",
      "Example:  ['a tractor suitable (or fit) for heavy duty', 'not an appropriate (or fit) time for flippancy']\n"
     ]
    }
   ],
   "source": [
    "s = wordnet.synsets(\"suitable\")\n",
    "print(\"Definition: \", s[0].definition())\n",
    "print(\"Example: \", s[0].examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synonyms: \n",
      " {'proficient', 'skilful', 'full', 'in_effect', 'estimable', 'honorable', 'meliorate', 'effective', 'improve', 'bettor', 'just', 'practiced', 'beneficial', 'ripe', 'sound', 'undecomposed', 'wagerer', 'punter', 'amend', 'dear', 'right', 'better', 'well', 'respectable', 'intimately', 'best', 'safe', 'easily', 'comfortably', 'near', 'honest', 'upright', 'advantageously', 'skillful', 'salutary', 'secure', 'ameliorate', 'adept', 'expert', 'serious', 'unspoilt', 'unspoiled', 'in_force', 'considerably', 'dependable', 'break', 'good', 'substantially'}\n",
      "antonyms: \n",
      " {'ill', 'worsen', 'worse', 'evil', 'badly', 'disadvantageously', 'bad'}\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "antonyms = []\n",
    "for s in wordnet.synsets(\"better\"):\n",
    "    for l in s.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "print(\"synonyms: \\n\", set(synonyms))\n",
    "print(\"antonyms: \\n\", set(antonyms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "http://www.nltk.org/api/nltk.stem.html\n",
    "\n",
    "http://en.wikipedia.org/wiki/Stemming\n",
    "\n",
    "https://wordnet.princeton.edu/wordnet/man/wndb.5WN.html#sect3\n",
    "\n",
    "http://www.nltk.org/howto/wordnet.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
